{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# Instalar librer√≠as necesarias\n",
        "!pip install keras-tuner"
      ],
      "metadata": {
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LVwnxU8gTrVO",
        "outputId": "228f74ef-0323-46e7-e47c-dda1c14b6aa5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting keras-tuner\n",
            "  Downloading keras_tuner-1.4.7-py3-none-any.whl.metadata (5.4 kB)\n",
            "Requirement already satisfied: keras in /usr/local/lib/python3.11/dist-packages (from keras-tuner) (3.8.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from keras-tuner) (24.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from keras-tuner) (2.32.3)\n",
            "Collecting kt-legacy (from keras-tuner)\n",
            "  Downloading kt_legacy-1.0.5-py3-none-any.whl.metadata (221 bytes)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.11/dist-packages (from keras->keras-tuner) (1.4.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from keras->keras-tuner) (2.0.2)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from keras->keras-tuner) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.11/dist-packages (from keras->keras-tuner) (0.0.8)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.11/dist-packages (from keras->keras-tuner) (3.13.0)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.11/dist-packages (from keras->keras-tuner) (0.14.1)\n",
            "Requirement already satisfied: ml-dtypes in /usr/local/lib/python3.11/dist-packages (from keras->keras-tuner) (0.4.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->keras-tuner) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->keras-tuner) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->keras-tuner) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->keras-tuner) (2025.1.31)\n",
            "Requirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.11/dist-packages (from optree->keras->keras-tuner) (4.12.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras->keras-tuner) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras->keras-tuner) (2.18.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->keras->keras-tuner) (0.1.2)\n",
            "Downloading keras_tuner-1.4.7-py3-none-any.whl (129 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m129.1/129.1 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading kt_legacy-1.0.5-py3-none-any.whl (9.6 kB)\n",
            "Installing collected packages: kt-legacy, keras-tuner\n",
            "Successfully installed keras-tuner-1.4.7 kt-legacy-1.0.5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from tensorflow.keras.preprocessing.sequence import TimeseriesGenerator\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense, Dropout, BatchNormalization\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "import keras_tuner as kt\n",
        "import os"
      ],
      "metadata": {
        "id": "wHmndiQsHNu2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"GPU Disponible:\", tf.config.list_physical_devices('GPU'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "brZRpYf7AT2v",
        "outputId": "5d257120-2baf-451d-db4c-b4193413cdcb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPU Disponible: []\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ========== Configuraci√≥n general ==========\n",
        "SEQ_LENGTH = 30\n",
        "VALIDATION_SPLIT = 0.1\n",
        "EPOCHS = 30\n",
        "BATCH_SIZE = 32\n",
        "MODEL_DIR = \"modelos_lstm_tuned\"\n",
        "TUNER_DIR = \"keras_tuner_dir\"\n",
        "os.makedirs(MODEL_DIR, exist_ok=True)\n",
        "\n",
        "# ========== Cargar y escalar datos ==========\n",
        "df = pd.read_csv(\"SP500_HMM_States.csv\")\n",
        "df['Date'] = pd.to_datetime(df['Date'])\n",
        "\n",
        "if 'Return' not in df.columns or 'State' not in df.columns:\n",
        "    raise ValueError(\"El archivo debe contener 'Return' y 'State'.\")\n",
        "\n",
        "scaler = StandardScaler()\n",
        "df['Return_scaled'] = scaler.fit_transform(df[['Return']])\n",
        "\n",
        "# ========== Crear generador ==========\n",
        "def create_generator(data_array):\n",
        "    split_idx = int(len(data_array) * (1 - VALIDATION_SPLIT))\n",
        "    train_data, val_data = data_array[:split_idx], data_array[split_idx:]\n",
        "    train_gen = TimeseriesGenerator(train_data, train_data, length=SEQ_LENGTH, batch_size=BATCH_SIZE)\n",
        "    val_gen = TimeseriesGenerator(val_data, val_data, length=SEQ_LENGTH, batch_size=BATCH_SIZE)\n",
        "    return train_gen, val_gen\n",
        "\n",
        "# ========== Definir espacio de hiperpar√°metros ==========\n",
        "def build_model(hp):\n",
        "    model = Sequential()\n",
        "\n",
        "    # LSTM 1\n",
        "    model.add(LSTM(\n",
        "        units=hp.Int('lstm_units_1', 32, 128, step=32),\n",
        "        return_sequences=True,\n",
        "        activation='tanh',\n",
        "        input_shape=(SEQ_LENGTH, 1)\n",
        "    ))\n",
        "\n",
        "    if hp.Boolean('use_batchnorm'):\n",
        "        model.add(BatchNormalization())\n",
        "\n",
        "    model.add(Dropout(hp.Float('dropout_1', 0.1, 0.5, step=0.1)))\n",
        "\n",
        "    # LSTM 2\n",
        "    model.add(LSTM(\n",
        "        units=hp.Int('lstm_units_2', 16, 64, step=16),\n",
        "        activation='tanh'\n",
        "    ))\n",
        "\n",
        "    model.add(Dropout(hp.Float('dropout_2', 0.1, 0.5, step=0.1)))\n",
        "    model.add(Dense(1))\n",
        "\n",
        "    model.compile(\n",
        "        optimizer=tf.keras.optimizers.Adam(\n",
        "            learning_rate=hp.Float('learning_rate', 1e-4, 1e-2, sampling='log')\n",
        "        ),\n",
        "        loss='mse'\n",
        "    )\n",
        "\n",
        "    return model\n",
        "\n",
        "# ========== Funci√≥n para optimizar y entrenar ==========\n",
        "def optimize_and_train(name, data_array):\n",
        "    print(f\"\\nüîç Optimizaci√≥n de hiperpar√°metros para: {name}\")\n",
        "\n",
        "    train_gen, val_gen = create_generator(data_array)\n",
        "\n",
        "    tuner = kt.Hyperband(\n",
        "        build_model,\n",
        "        objective='val_loss',\n",
        "        max_epochs=EPOCHS,\n",
        "        factor=3,\n",
        "        directory=TUNER_DIR,\n",
        "        project_name=f'tuning_{name}'\n",
        "    )\n",
        "\n",
        "    tuner.search(train_gen, validation_data=val_gen, epochs=EPOCHS,\n",
        "                 callbacks=[EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)],\n",
        "                 verbose=1)\n",
        "\n",
        "    best_hp = tuner.get_best_hyperparameters(1)[0]\n",
        "\n",
        "    print(f\"\\n‚úÖ Mejores hiperpar√°metros para {name}:\")\n",
        "    for k, v in best_hp.values.items():\n",
        "        print(f\"  - {k}: {v}\")\n",
        "\n",
        "    # Entrenar modelo final\n",
        "    model = tuner.hypermodel.build(best_hp)\n",
        "    model.fit(train_gen, validation_data=val_gen, epochs=EPOCHS,\n",
        "              callbacks=[EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)],\n",
        "              verbose=1)\n",
        "\n",
        "    model.save(f\"{MODEL_DIR}/LSTM_{name}.h5\")\n",
        "    print(f\"üíæ Modelo guardado: {MODEL_DIR}/LSTM_{name}.h5\")\n",
        "\n"
      ],
      "metadata": {
        "id": "MzzbnnbGAT8A",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ========== Entrenar modelo general ==========\n",
        "full_data = df['Return_scaled'].values.reshape(-1, 1)\n",
        "optimize_and_train(\"Full_Series\", full_data)\n",
        "\n",
        "# ========== Entrenar modelos por estado ==========\n",
        "for state in sorted(df['State'].unique()):\n",
        "    state_data = df[df['State'] == state]['Return_scaled'].values\n",
        "    if len(state_data) <= SEQ_LENGTH + 10:\n",
        "        print(f\"‚ö†Ô∏è Estado {state} omitido (muy pocos datos).\")\n",
        "        continue\n",
        "\n",
        "    try:\n",
        "        state_array = state_data.reshape(-1, 1)\n",
        "        optimize_and_train(f\"State_{state}\", state_array)\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Error en State {state}: {e}\")\n"
      ],
      "metadata": {
        "id": "F4PgnXTqS4Sr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0bd22783-2679-4b91-d561-d5c5daf23379"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 90 Complete [00h 01m 51s]\n",
            "val_loss: 0.9437922835350037\n",
            "\n",
            "Best val_loss So Far: 0.9328762292861938\n",
            "Total elapsed time: 00h 44m 40s\n",
            "\n",
            "‚úÖ Mejores hiperpar√°metros para State_3:\n",
            "  - lstm_units_1: 128\n",
            "  - use_batchnorm: True\n",
            "  - dropout_1: 0.30000000000000004\n",
            "  - lstm_units_2: 48\n",
            "  - dropout_2: 0.1\n",
            "  - learning_rate: 0.0001740001673618082\n",
            "  - tuner/epochs: 30\n",
            "  - tuner/initial_epoch: 10\n",
            "  - tuner/bracket: 1\n",
            "  - tuner/round: 1\n",
            "  - tuner/trial_id: 0075\n",
            "Epoch 1/30\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 63ms/step - loss: 1.3800 - val_loss: 0.9837\n",
            "Epoch 2/30\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 59ms/step - loss: 1.3714 - val_loss: 0.9824\n",
            "Epoch 3/30\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 57ms/step - loss: 1.3031 - val_loss: 0.9825\n",
            "Epoch 4/30\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 56ms/step - loss: 1.2672 - val_loss: 0.9870\n",
            "Epoch 5/30\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 76ms/step - loss: 1.3024 - val_loss: 0.9795\n",
            "Epoch 6/30\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 56ms/step - loss: 1.3769 - val_loss: 0.9928\n",
            "Epoch 7/30\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 57ms/step - loss: 1.2795 - val_loss: 0.9813\n",
            "Epoch 8/30\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 76ms/step - loss: 1.3918 - val_loss: 0.9765\n",
            "Epoch 9/30\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 57ms/step - loss: 1.3059 - val_loss: 0.9570\n",
            "Epoch 10/30\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 57ms/step - loss: 1.2527 - val_loss: 0.9583\n",
            "Epoch 11/30\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 76ms/step - loss: 1.3145 - val_loss: 0.9487\n",
            "Epoch 12/30\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 56ms/step - loss: 1.2953 - val_loss: 0.9644\n",
            "Epoch 13/30\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 55ms/step - loss: 1.2927 - val_loss: 1.0048\n",
            "Epoch 14/30\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 77ms/step - loss: 1.3769 - val_loss: 0.9629\n",
            "Epoch 15/30\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 56ms/step - loss: 1.2489 - val_loss: 0.9517\n",
            "Epoch 16/30\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 56ms/step - loss: 1.2607 - val_loss: 0.9936\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üíæ Modelo guardado: modelos_lstm_tuned/LSTM_State_3.h5\n",
            "\n",
            "üîç Optimizaci√≥n de hiperpar√°metros para: State_4\n",
            "‚ùå Error en State 4: `start_index+length=30 > end_index=19` is disallowed, as no part of the sequence would be left to be used as current step.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "shutil.make_archive('/content/keras_tuner_dir', 'zip', '/content/keras_tuner_dir')\n",
        "shutil.make_archive('/content/modelos_lstm_tuned', 'zip', '/content/modelos_lstm_tuned')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "1hdOcqid5lZ8",
        "outputId": "4cf5e7ac-853c-4333-df46-6a9dfd1e9aa2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_8158ace8-e891-47d7-b19c-3f9c23682be4\", \"keras_tuner_dir.zip\", 205948912)"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}